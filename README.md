# Vision-Language-Audio

#VQA: Visual Question Answer:

Visual Question Answering with Question Representation Update (QRU)
Paper: https://papers.nips.cc/paper/6261-visual-question-answering-with-question-representation-update-qru.pdf


Survey
FVQA: Fact-based Visual Question Answering
https://arxiv.org/pdf/1606.05433.pdf

#VQG
1.Generating Natural Questions About an Image

Paper: https://arxiv.org/pdf/1603.06059.pdf



2. Automatic Generation of Grounded Visual Questions 

Paper:https://www.ijcai.org/proceedings/2017/0592.pdf

3. Neural Self Talk: Image Understanding via Continuous Questioning and Answering

Paper: https://pdfs.semanticscholar.org/6861/552bf6730529d3fac5d6f2bb7e0f491edea2.pdf

4. Question Generation via Overgenerating Transformations and Ranking

paper: https://www.lti.cs.cmu.edu/sites/default/files/cmulti09013.pdf

Code:
1. https://github.com/JamesChuanggg/VQG-tensorflow

Blog: 

http://cjds.github.io/image%20recognition/machine%20learning/2016/05/02/Visual-Question-Generation/

#Dialog
1. Visual Dialog

paper: https://arxiv.org/pdf/1611.08669.pdf

2. Deep Reinforcement Learning for Dialogue Generation

paper: https://arxiv.org/pdf/1606.01541.pdf

Multi-Layer Dialog Generation for Non-Visual Web Access

Paper: http://dl.acm.org/citation.cfm?id=1196153

http://delivery.acm.org/10.1145/1200000/1196153/p20-borodin.pdf?ip=103.246.106.9&id=1196153&acc=ACTIVE%20SERVICE&key=045416EF4DDA69D9%2E6454B2DFDB9CC807%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=940869340&CFTOKEN=46601584&__acm__=1502957609_93d381d4acab13ddf0d35c51a1fa5605

#Image Caption
1. Improved Image Captioning via Policy Gradient optimization of SPIDEr

Paper: https://arxiv.org/pdf/1612.00370.pdf

#Movie 
1. A Dataset for Movie Description

Paper:: https://link.springer.com/article/10.1007/s11263-016-0987-1

2. The Long-Short Story of Movie Description.

Paper: https://link.springer.com/chapter/10.1007/978-3-319-24947-6_17

3. A Dataset for Movie Description

Paper: http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Rohrbach_A_Dataset_for_2015_CVPR_paper.pdf

4. Generating Descriptions with Grounded and Co-Referenced People

Paper: https://arxiv.org/abs/1704.01518

6. A dataset and exploration of models for understanding video data through fill-in-the-blank question-answering

Paper: https://arxiv.org/abs/1611.07810

5. Generation and grounding of natural language descriptions for visual data

link: http://pubman.mpdl.mpg.de/pubman/faces/viewItemOverviewPage.jsp?itemId=escidoc:2450719

6.Coherent Multi-sentence Video Description with Variable Level of Detail

Paper:https://link.springer.com/chapter/10.1007/978-3-319-11752-2_15

7. Grounding of Textual Phrases in Images by Reconstruction

Paper:https://link.springer.com/chapter/10.1007/978-3-319-46448-0_49

8. Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data

Paper: https://link.springer.com/article/10.1007/s11263-015-0851-8

#CommonSense

Commonsense in Parts: Mining Part-Whole Relations from the Web and Image Tags

Paper: http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12337/11590

Other:
Multiple Object Recognition with Visual Attention
https://arxiv.org/abs/1412.7755



Good Slide:

1. https://www.slideshare.net/hemanth4/ayurveda-simplified



When Not to Use Deep Learning
http://www.scoop.it/t/data-science-58
http://www.datasciencecentral.com/profiles/blogs/when-not-to-use-deep-learning


Reinforcement learning for complex goals, using TensorFlow

http://www.scoop.it/t/data-science-58


